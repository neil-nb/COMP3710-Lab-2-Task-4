{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import imageio.v2 as image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Warning: CUDA not found. Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OasisDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Custom PyTorch dataset for loading OASIS images and labels.\n",
    "\n",
    "    Attributes (Where N - batch, C - channels, D - depth, H - height, W - width):\n",
    "        images (torch.Tensor): Image tensors of shape (N, C, H, W).\n",
    "        labels (torch.Tensor): Label tensors of shape (N, H, W, C) or (N, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels):\n",
    "        # Convert to torch tensors and ensure channels-first format\n",
    "        self.images = torch.from_numpy(images).permute(0, 3, 1, 2)  # (N, H, W, 1) â†’ (N, 1, H, W)\n",
    "        self.labels = torch.from_numpy(labels)  # (N, H, W, C) or (N, H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "    \n",
    "def load_training(path):\n",
    "    \"\"\"\n",
    "    Load training images from the specified directory.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    for filename in glob.glob(path + \"/*.png\"):\n",
    "        im = image.imread(filename)\n",
    "        image_list.append(im)\n",
    "    print(\"train_X shape:\", np.array(image_list).shape)\n",
    "    return np.array(image_list, dtype=np.float32)\n",
    "\n",
    "def process_training(data_set):\n",
    "    \"\"\"\n",
    "    Normalise and reshape training images.\n",
    "    \"\"\"\n",
    "    data_set = data_set.astype(np.float32)\n",
    "    if data_set.max() > 1.0:\n",
    "        data_set = data_set / 255.0\n",
    "    data_set = data_set[:, :, :, np.newaxis]  # (N, H, W, 1)\n",
    "    return data_set\n",
    "\n",
    "def load_labels(path):\n",
    "    \"\"\"\n",
    "    Load label masks and map pixel values to integer class IDs.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    for filename in glob.glob(path + \"/*.png\"):\n",
    "        im = image.imread(filename)\n",
    "        one_hot = np.zeros((im.shape[0], im.shape[1]))\n",
    "        for i, unique_value in enumerate(np.unique(im)):\n",
    "            one_hot[:, :][im == unique_value] = i\n",
    "        image_list.append(one_hot)\n",
    "    print(\"train_y shape:\", np.array(image_list).shape)\n",
    "    return np.array(image_list, dtype=np.uint8)\n",
    "\n",
    "def process_labels(seg_data):\n",
    "    \"\"\"\n",
    "    Convert integer label masks into one-hot encoded format.\n",
    "    \"\"\"\n",
    "    onehot_Y = []\n",
    "    for n in range(seg_data.shape[0]):\n",
    "        im = seg_data[n]\n",
    "        n_classes = 4\n",
    "        one_hot = np.zeros((im.shape[0], im.shape[1], n_classes), dtype=np.uint8)\n",
    "        for i, unique_value in enumerate(np.unique(im)):\n",
    "            one_hot[:, :, i][im == unique_value] = 1\n",
    "        onehot_Y.append(one_hot)\n",
    "    onehot_Y = np.array(onehot_Y)\n",
    "    print(\"Labels shape:\", onehot_Y.shape)\n",
    "    return onehot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = process_training(load_training(\"oasis/keras_png_slices_data/keras_png_slices_train\"))\n",
    "train_Y = process_labels(load_labels(\"oasis/keras_png_slices_data/keras_png_slices_seg_train\"))\n",
    "train_dataset = OasisDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_X = process_training(load_training(\"oasis/keras_png_slices_data/keras_png_slices_test\"))\n",
    "test_Y = process_labels(load_labels(\"oasis/keras_png_slices_data/keras_png_slices_seg_test\"))\n",
    "test_dataset = OasisDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a409470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A two-layer convolutional block used in UNet.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3c766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52067263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf58105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3825a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b79897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a976d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81312ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

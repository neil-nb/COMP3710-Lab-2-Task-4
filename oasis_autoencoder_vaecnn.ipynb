{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f07004f",
      "metadata": {
        "id": "3f07004f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8def32b",
      "metadata": {
        "id": "c8def32b"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning CUDA not Found. Using CPU\")\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 8\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac97b331",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac97b331",
        "outputId": "0e540e41-94fa-4862-a903-f9614e5cdaf5"
      },
      "outputs": [],
      "source": [
        "#Data\n",
        "print(\"> Setup dataset\")\n",
        "transform = transforms.Compose([transforms.ToTensor()])  # Only ToTensor, which normalizes to [0,1]\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='/mnt/d/uqwdai1/data/rdm_backed/pytorch/', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True) #num_workers=6\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='/mnt/d/uqwdai1/data/rdm_backed/pytorch/', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False) #num_workers=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a952a95e",
      "metadata": {
        "id": "a952a95e"
      },
      "outputs": [],
      "source": [
        "class CNNVAE(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder (same as before but outputs mean and log_var)\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 28x28 -> 28x28\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 14x14 -> 14x14\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 14x14 -> 7x7\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # 7x7 -> 7x7\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),  # 7x7 -> 4x4\n",
        "\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Latent space parameters\n",
        "        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)      # Mean\n",
        "        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)  # Log variance\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),  # Reshape to (batch, 128, 4, 4)\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 4x4 -> 8x8\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # 8x8 -> 16x16\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1),  # 16x16 -> 16x16\n",
        "            nn.Upsample(size=(28, 28), mode='bilinear', align_corners=False),  # 16x16 -> 28x28\n",
        "            nn.Sigmoid()  # Output in [0, 1] for image reconstruction\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Encode input to latent parameters\"\"\"\n",
        "        h = self.encoder_conv(x)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick: sample from N(mu, var) using N(0,1)\"\"\"\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return mu + eps * std\n",
        "        else:\n",
        "            return mu  # Use mean for inference. Using mu (mean) rather than sampling from the full distribution because:\n",
        "                        # It provides deterministic, reproducible results\n",
        "                        # The mean represents the \"most likely\" latent representation\n",
        "                        # It avoids noise that could make interpolation less smooth\n",
        "\n",
        "    def decode(self, z):\n",
        "        \"\"\"Decode latent variable to reconstruction\"\"\"\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "def vae_loss_function(recon_x, x, mu, logvar, beta=1.0):\n",
        "    \"\"\"\n",
        "    VAE loss = Reconstruction loss + KL divergence\n",
        "    beta: weight for KL divergence (beta-VAE)\n",
        "    \"\"\"\n",
        "    # Reconstruction loss (Binary Cross Entropy)\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "\n",
        "    # KL divergence loss\n",
        "    # KLD = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + beta * KLD, BCE, KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72aedd91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "72aedd91",
        "outputId": "e1943a30-6529-4456-cfdc-826e40b20eba"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Train the VAE\n",
        "vae = CNNVAE(latent_dim=32).to(device)\n",
        "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "num_vae_epochs = 10\n",
        "beta = 1.0  # Beta parameter for beta-VAE (1.0 = standard VAE)\n",
        "\n",
        "print(\"Training VAE...\")\n",
        "for epoch in range(num_vae_epochs):\n",
        "    vae.train()\n",
        "    total_loss = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0\n",
        "\n",
        "    for batch_idx, (images, _) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        recon_images, mu, logvar = vae(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss, bce, kld = vae_loss_function(recon_images, images, mu, logvar, beta)\n",
        "\n",
        "        # Backward pass\n",
        "        vae_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        vae_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_bce += bce.item()\n",
        "        total_kld += kld.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    avg_bce = total_bce / len(train_loader.dataset)\n",
        "    avg_kld = total_kld / len(train_loader.dataset)\n",
        "\n",
        "    print(f'VAE Epoch [{epoch+1}/{num_vae_epochs}], Loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KLD: {avg_kld:.4f}')\n",
        "\n",
        "    # Visualize reconstructions every few epochs\n",
        "    if (epoch + 1) % 1 == 0 or epoch == 0:\n",
        "        vae.eval()\n",
        "        with torch.no_grad():\n",
        "            test_images, _ = next(iter(test_loader))\n",
        "            test_images = test_images.to(device)\n",
        "            recon_images, _, _ = vae(test_images)\n",
        "\n",
        "            # Plot original vs reconstructed\n",
        "            fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
        "            for i in range(10):\n",
        "                # Original\n",
        "                axes[0, i].imshow(test_images[i].cpu().squeeze(), cmap='gray')\n",
        "                axes[0, i].axis('off')\n",
        "                if i == 0:\n",
        "                    axes[0, i].set_ylabel('Original', fontsize=12)\n",
        "\n",
        "                # Reconstructed\n",
        "                axes[1, i].imshow(recon_images[i].cpu().squeeze(), cmap='gray')\n",
        "                axes[1, i].axis('off')\n",
        "                if i == 0:\n",
        "                    axes[1, i].set_ylabel('Reconstructed', fontsize=12)\n",
        "\n",
        "            plt.suptitle(f'VAE Reconstructions - Epoch {epoch+1}', fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6722168b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6722168b",
        "outputId": "92b4504b-cbd0-4a8e-ae60-7dc7f63a84f7"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# Generate new samples from the VAE\n",
        "print(\"Generating new samples from VAE...\")\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    # Sample from standard normal distribution\n",
        "    z = torch.randn(64, vae.latent_dim).to(device)\n",
        "    generated_images = vae.decode(z)\n",
        "\n",
        "    # Plot generated samples\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            idx = i * 8 + j\n",
        "            axes[i, j].imshow(generated_images[idx].cpu().squeeze(), cmap='gray')\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "    plt.suptitle('Generated Samples from VAE', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59b7849",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "a59b7849",
        "outputId": "a82d2c78-9e81-4eb3-84be-e99940c6774f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Compare latent space interpolation\n",
        "print(\"Latent space interpolation...\")\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    # Get random batch of test images\n",
        "    test_images, test_labels = next(iter(test_loader))\n",
        "    test_images = test_images.to(device)\n",
        "\n",
        "    # Randomly select two different digits\n",
        "    available_indices = list(range(len(test_labels)))\n",
        "    idx1 = random.choice(available_indices)\n",
        "\n",
        "    # Find a different digit\n",
        "    different_digits = [i for i in available_indices if test_labels[i] != test_labels[idx1]]\n",
        "    if different_digits:\n",
        "        idx2 = random.choice(different_digits)\n",
        "    else:\n",
        "        # Fallback if somehow all digits are the same (very unlikely)\n",
        "        idx2 = (idx1 + 1) % len(test_labels)\n",
        "\n",
        "    print(f\"Interpolating between digit {test_labels[idx1].item()} and digit {test_labels[idx2].item()}\")\n",
        "\n",
        "    # Encode the two images\n",
        "    mu1, _ = vae.encode(test_images[idx1:idx1+1])\n",
        "    mu2, _ = vae.encode(test_images[idx2:idx2+1])\n",
        "\n",
        "    # Interpolate between the two latent vectors\n",
        "    n_steps = 10\n",
        "    interpolated_images = []\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        alpha = i / (n_steps - 1)\n",
        "        z_interp = (1 - alpha) * mu1 + alpha * mu2\n",
        "        img_interp = vae.decode(z_interp)\n",
        "        interpolated_images.append(img_interp)\n",
        "\n",
        "    # Plot interpolation\n",
        "    fig, axes = plt.subplots(1, n_steps, figsize=(20, 2))\n",
        "    for i in range(n_steps):\n",
        "        axes[i].imshow(interpolated_images[i].cpu().squeeze(), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Step {i+1}', fontsize=10)\n",
        "\n",
        "    plt.suptitle(f'Latent Space Interpolation: Digit {test_labels[idx1]} â†’ Digit {test_labels[idx2]}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e091c53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1e091c53",
        "outputId": "d9b9ecbe-1e07-4d09-e4f1-15a694b1dc70"
      },
      "outputs": [],
      "source": [
        "# Create a 2D manifold visualization of digits\n",
        "print(\"Creating 2D manifold of digits...\")\n",
        "\n",
        "def plot_digit_manifold(vae, n_grid=15, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Plot a 2D manifold of digits by sampling from a grid in latent space\n",
        "    \"\"\"\n",
        "    vae.eval()\n",
        "\n",
        "    # Create a grid of points in 2D latent space\n",
        "    # We'll use the first 2 dimensions of the latent space\n",
        "    grid_x = np.linspace(-3, 3, n_grid)\n",
        "    grid_y = np.linspace(-3, 3, n_grid)\n",
        "\n",
        "    fig, axes = plt.subplots(n_grid, n_grid, figsize=figsize)\n",
        "\n",
        "    # Randomly select which 2 dimensions to use for the manifold\n",
        "    dim1 = np.random.randint(0, vae.latent_dim)\n",
        "    dim2 = np.random.randint(0, vae.latent_dim)\n",
        "    while dim2 == dim1:\n",
        "        dim2 = np.random.randint(0, vae.latent_dim)\n",
        "\n",
        "    print(f\"Using latent dimensions {dim1} and {dim2} for manifold\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, y in enumerate(grid_y):\n",
        "            for j, x in enumerate(grid_x):\n",
        "                # Create latent vector with small random noise in other dimensions\n",
        "                z = torch.randn(1, vae.latent_dim).to(device) * 0.1  # Small noise\n",
        "                z[0, dim1] = x\n",
        "                z[0, dim2] = y\n",
        "\n",
        "                # Decode the latent vector\n",
        "                decoded_img = vae.decode(z)\n",
        "\n",
        "                # Plot the decoded image\n",
        "                axes[i, j].imshow(decoded_img.cpu().squeeze(), cmap='gray')\n",
        "                axes[i, j].axis('off')\n",
        "\n",
        "    plt.suptitle('2D Manifold of Digits (Latent Space Dimensions 0 & 1)', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Import numpy if not already imported\n",
        "import numpy as np\n",
        "\n",
        "# Create the manifold visualization\n",
        "plot_digit_manifold(vae, n_grid=15)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
